---
layout: post

title:  "혼자 공부하는 머신러닝 03"

categories : Machine_Learning

tag : [python, ml,머신러닝, sklearn, 회귀, 사이킷런, 넘파이, numpy, 로지스틱]

---

7개 종류의 생선을 랜덤하게 럭키백에 넣고

길이, 대각선, 높이, 두께, 무게 5개의 특성을 통해서 이 생선이 7개의 종류 중 어떤 것일지 확률을 구하기 



### 1. 데이터 세팅

```python
import pandas as pd

fish = pd.read_csv('https://bit.ly/fish_csv')

pd.unique(fish['Species'])
##array(['Bream', 'Roach', 'Whitefish', 'Parkki', 'Perch', 'Pike', 'Smelt'],dtype=object)


fish_input = fish.iloc[:,1:].to_numpy()
fish_target = fish['Species'].to_numpy()

from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    fish_input, fish_target, random_state=42
)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(train_input)
train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)
```



.

### 2. 로지스틱 이진 분류

```python
##데이터 세트 중에 도미, 빙어만 쓰기 위해 정리
## Bream = 도미, Smelt = 빙어
bream_smelt_indexes = (train_target=='Bream') | (train_target=='Smelt')
train_bream_smelt = train_scaled[bream_smelt_indexes]
target_bream_smelt = train_target[bream_smelt_indexes]

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(train_bream_smelt, target_bream_smelt)

print(lr.predict(train_bream_smelt[:5]))
## ['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']
```

```python

print(lr.classes_) 
## array(['Bream', 'Smelt'], dtype=object)
### Smelt 가 1로 양성 클래스


print(lr.predict_proba(train_bream_smelt[:5]))
### 첫번째가 음성 클래스(0) 에 대한 확률, 두번째 열이 양성 클래스(1)에 대한 확률
## 무엇이 음성이고 양성인지는 lr.classes_ 로 확인
[[0.99759855 0.00240145]
 [0.02735183 0.97264817]
 [0.99486072 0.00513928]
 [0.98584202 0.01415798]
 [0.99767269 0.00232731]]

## 첫번째 데이터 도미일 확률 99퍼, 빙어일 확률 0.2퍼


decisions = lr.decision_function(train_bream_smelt[:5])


## 시그모이드 함수로 확률 값 얻기
from scipy.special import expit
print(expit(decisions)) ## [0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]

### (lr.predict_proba(train_bream_smelt[:5])) 로 했을 때 두번째 열의 값, 양성 클래스에 대한 확률과 동일
### decision_function 매서드는 양성 클래스에 대한 z 값을 반환
[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
```

.


### 3. 로지스틱 다중 분류

```python
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(C=20, max_iter=1000)
lr.fit(train_scaled, train_target)
print(lr.score(train_scaled, train_target)) ## 0.9327731092436975
print(lr.score(test_scaled, test_target)) ## 0.925

## 과소적합이나 과대적합이 보이지 않음
```

로지스틱에서 반복횟수는 기본적으로 100. 

숫자가 적어서 1000으로 늘려서 세팅



규제는 L2 Norm을 사용하는 규제를 자동으로 적용.

규제의 강도를 조절하는 게 C 값. 기본값은 1.

C값이 올라가면 규제가 약해지고, 낮아지면 규제가 강해짐.

선형회귀의 alpha와 반대로 작용.

.

```python
lr.predict(test_scaled[:5])
# array(['Perch', 'Smelt', 'Pike', 'Roach', 'Perch'], dtype=object)

import numpy as np

proba= lr.predict_proba(test_scaled[:5])
print(np.round(proba, decimals=3))

[[0.    0.014 0.841 0.    0.136 0.007 0.003]
 [0.    0.003 0.044 0.    0.007 0.946 0.   ]
 [0.    0.    0.034 0.935 0.015 0.016 0.   ]
 [0.011 0.034 0.306 0.007 0.567 0.    0.076]
 [0.    0.    0.904 0.002 0.089 0.002 0.001]]


print(lr.classes_)
# array(['Bream', 'Parkki', 'Perch', 'Pike', 'Roach', 'Smelt', 'Whitefish'],dtype=object)

decision = lr.decision_function(test_scaled[:5])
print(np.round(decision, decimals=2))

[[ -6.5    1.03   5.16  -2.73   3.34   0.33  -0.63]
 [-10.86   1.93   4.77  -2.4    2.98   7.84  -4.26]
 [ -4.34  -6.23   3.17   6.49   2.36   2.42  -3.87]
 [ -0.68   0.45   2.65  -1.19   3.26  -5.75   1.26]
 [ -6.4   -1.99   5.82  -0.11   3.5   -0.11  -0.71]]


### 다항일 때는 시그모이드 대신 소프트맥스 함수 사용

from scipy.special import softmax

proba = softmax(decision, axis=1)

print(np.round(proba, decimals=3))

[[0.    0.014 0.841 0.    0.136 0.007 0.003]
 [0.    0.003 0.044 0.    0.007 0.946 0.   ]
 [0.    0.    0.034 0.935 0.015 0.016 0.   ]
 [0.011 0.034 0.306 0.007 0.567 0.    0.076]
 [0.    0.    0.904 0.002 0.089 0.002 0.001]]
```