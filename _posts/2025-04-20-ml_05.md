---
layout: post

title:  "혼자 공부하는 머신러닝 05"
categories : Machine_Learning

tag : [python, ml,머신러닝, sklearn, 사이킷런, 결정트리]

---



### 1. 결정트리

레드 와인, 화이트 와인 표시가 누락된 상태에서

캔에 적힌 알코올 도수, 당도, pH값으로 구별하는 방법

```python
## 로지스틱 회귀로 분류
import pandas as pd
wine = pd.read_csv('https://bit.ly/wine-date')
wine.info()

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 6497 entries, 0 to 6496
Data columns (total 4 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   alcohol  6497 non-null   float64
 1   sugar    6497 non-null   float64
 2   pH       6497 non-null   float64
 3   class    6497 non-null   float64
dtypes: float64(4)

### class가 0이면 레드 와인, 1이면 화이트 와인

data = wine.iloc[:,:-1].to_numpy()
target= wine['class'].to_numpy()

from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42
)

print(train_input.shape, test_input.shape) #(5197, 3) (1300, 3)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(train_input)

train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(train_scaled, train_target)
print(lr.score(train_scaled, train_target)) #0.7808350971714451
print(lr.score(test_scaled, test_target)) #0.7776923076923077


print(lr.coef_, lr.intercept_) #[[ 0.51268071  1.67335441 -0.68775646]] [1.81773456] 데이터는 알콜, 설탕, pH
print(lr.classes_) #[0. 1.] 0이면 레드 와인, 1이면 화이트 와인

```


로지스틱 분류 결과로 볼 때 알콜 도수, 당도가 높으면 화이트 와인일 확률이 높고 pH가 높을 수록 레드 와인이 될 확률이 높음 

하지만 설명하기가 어려움 coef_, intercept 결과가 직관적이지 않음

다항 특성을 추가하면 더 설명하기 어려움



이런 문제를 해결하기 위한 결정 트리

```python
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)
print(dt.score(train_scaled, train_target)) #0.996921300750433
print(dt.score(test_scaled, test_target)) #0.8592307692307692

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(10,7))
plot_tree(dt)
plt.show()
```

![tree1](../../../../images/2025-04-20-ml_05/tree1.png)

max_depth를 설정하지 않을 경우 끝까지 감

.

.

```python
plt.figure(figsize=(10,7))
plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol','sugar','pH'])
##filled = True를 하면 양성 클래스를 파랑색으로 칠해줌
plt.show()
```

![tree2](../../../../images/2025-04-20-ml_05/tree2.png)

.

.

```python
## 가지치기
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_scaled, train_target)

plt.figure(figsize=(20,15))
plot_tree(dt, filled =True, feature_names=['alcohol','sugar','pH'])
plt.show()
#색이 진할수록 양성 클래스가 모여있음
```

![tree3](../../../../images/2025-04-20-ml_05/tree3.png)

.

.

```python
#스케일 조정을 하지 않고 사용 -> 특성값이 원본 데이터 값으로 나와서 이해하기 쉬움
dt.fit(train_input, train_target)

plt.figure(figsize=(20,15))
plot_tree(dt, filled =True, feature_names=['alcohol','sugar','pH'])
plt.show()
## sugar가 1.625보다 크고 alcohol은 11.025보다 작거나 같으면 레드와인 (레드 와인이 음성 클래스)
```

![tree4](../../../../images/2025-04-20-ml_05/tree4.png)



### 2. 교차 검증