---
layout: post

title:  "리스트에서 하나씩 지우며 크롤링"

categories : Python

tag : [python, 크롤링, pop]
---







특정 사이트에 로그인 selenium 처리하고

미리 준비한 id별 정보를 검색하여 

검색으로 나온 결과 크롤링 

```python

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from bs4 import BeautifulSoup as bs
import pandas as pd
import time

chrome_driver = 'chromedriver 있는 path'
driver = webdriver.Chrome(chrome_driver)

url = '기본주소'

driver.get(url)
driver.implicitly_wait(3)


#최초 접속 시 로그인 필요
username = 'id'
password = '비번'
driver.find_element(By.ID, 'username').send_keys(username)
driver.find_element(By.ID, 'password').send_keys(password)

wait = WebDriverWait(driver, 10)

login_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME,'btn_login')))
login_button.click()

driver.implicitly_wait(3)


#원하는 크롤링 id 리스트
id_list=["a","b","c"]

#최종 파일
final_list=[]


#id 리스트에 요소가 있는 동안 반복문
while id_list:
    
    #정보를 담을 임시 리스트
    content_list=[]
    
    id=id_list[0]
    
    
    ##최초에는 로그인 창이 달라서 try, except 처리
    try:
        driver.find_element(By.XPATH,'//*[@id="content"]/div[1]/div/div[1]/div[2]/form/input').send_keys(id)
        driver.implicitly_wait(3)
    except:
        driver.find_element(By.XPATH,'//*[@id="content"]/div[1]/form/input').send_keys(id)
        driver.implicitly_wait(3)
    
    
    #id 검색
    search_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME,'btn_search')))
    search_button.click()
    driver.implicitly_wait(3)
    
    
    #검색 결과 wait
    try:
        element_present = EC.presence_of_element_located((By.CLASS_NAME, 'search-section-wrap'))
        WebDriverWait(driver, 10).until(element_present)
    except :
        pass
    
    
    
    html = driver.page_source
    soup = bs(html, 'html.parser')
    
    
    
    #유저가 없을 경우 pass 하고 content_list에 퇴사 처리
    try:
        ul = soup.find('ul',{'class':'search-section-user-list'})
        span_tags = ul.find_all('span')

        for span_text in span_tags:
            text = span_text.get_text()
            content_list.append(text)
    except:
        content_list =['퇴사','퇴사','퇴사','퇴사','퇴사']  
     
    #원하는 정보는 pair 처리
    pair = (id, content_list[0],content_list[2],content_list[4])
    print(pair)
    
 
    final_list.append(pair)
    
    #이번에 검색한 id는 없애버리고 while문 반복
    removed_value = id_list.pop(0)
    
    #검색 창에서 이전에 검색했던 id 삭제
    clear_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME,'btn_clear')))
    clear_button.click()
    driver.implicitly_wait(3)




df = pd.DataFrame(final_list, columns=['검색id','name', 'id','team'])
# df.to_excel("./email_name_team.xlsx")

print(df)
```

